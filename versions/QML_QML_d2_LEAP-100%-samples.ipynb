{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Quantum-Classical Hybrid Model using BERT and Quantum Kernel SVM for GoEmotions Dataset\n",
        "\n",
        "# Step 1: Environment Setup (Google Colab)\n",
        "!pip uninstall -y jax jaxlib\n",
        "!pip install jax==0.4.28 jaxlib==0.4.28 --quiet\n",
        "!pip install pennylane seaborn tensorflow-datasets scikit-learn==1.6.1 transformers --upgrade --quiet"
      ],
      "metadata": {
        "id": "RWUDcjiWxoY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import Required Libraries\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import numpy as onp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import tensorflow_datasets as tfds\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "CelrQgOGzeOX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load GoEmotions Dataset\n",
        "print(\"Loading GoEmotions dataset...\")\n",
        "dataset, info = tfds.load('goemotions', with_info=True)\n",
        "train_dataset = dataset['train']\n",
        "\n",
        "# Define emotion labels in the correct order\n",
        "emotion_labels = [\n",
        "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion',\n",
        "    'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
        "    'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'neutral',\n",
        "    'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise'\n",
        "]\n",
        "\n",
        "texts, labels = [], []\n",
        "for example in tfds.as_numpy(train_dataset):\n",
        "    texts.append(example['comment_text'].decode('utf-8'))\n",
        "    for idx, label in enumerate(emotion_labels):\n",
        "        if example[label]:\n",
        "            labels.append(idx)\n",
        "            break\n",
        "    else:\n",
        "        labels.append(20)\n",
        "\n",
        "n_classes = 28"
      ],
      "metadata": {
        "id": "Sr_bB88OzxHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: BERT Embedding Extraction\n",
        "print(\"Extracting BERT embeddings...\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to compute BERT [CLS] embeddings\n",
        "def bert_embed(sentences):\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        outputs = model(**inputs)\n",
        "        return outputs.last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "batch_size = 64\n",
        "bert_embeddings = []\n",
        "for i in range(0, len(texts), batch_size):\n",
        "    bert_embeddings.append(bert_embed(texts[i:i+batch_size]))\n",
        "X = onp.vstack(bert_embeddings)\n",
        "y = onp.array(labels)"
      ],
      "metadata": {
        "id": "ZBM0Z6_n0tQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Dimensionality Reduction\n",
        "print(\"Reducing BERT embedding dimensions using PCA...\")\n",
        "pca = PCA(n_components=16)\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gnkuStN1FGf",
        "outputId": "ca3a68d6-a9a3-4423-9dc2-4fefcd0aad36"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reducing BERT embedding dimensions using PCA...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Quantum Kernel Setup\n",
        "n_qubits = 16\n",
        "dev = qml.device('default.qubit', wires=n_qubits)\n",
        "\n",
        "def feature_map(x):\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(x[i], wires=i)\n",
        "    for i in range(n_qubits - 1):\n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "    qml.CNOT(wires=[n_qubits - 1, 0])\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def kernel_circuit(x1, x2):\n",
        "    feature_map(x1)\n",
        "    qml.adjoint(feature_map)(x2)\n",
        "    return qml.probs(wires=range(n_qubits))\n",
        "\n",
        "# Quantum kernel function\n",
        "def quantum_kernel(X1, X2):\n",
        "    kernel = np.zeros((len(X1), len(X2)))\n",
        "    for i in range(len(X1)):\n",
        "        for j in range(len(X2)):\n",
        "            kernel[i, j] = np.abs(kernel_circuit(X1[i], X2[j])[0])\n",
        "    return kernel"
      ],
      "metadata": {
        "id": "7gfXxVfLFUuc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Compute Quantum Kernel Matrices\n",
        "print(\"Computing quantum kernel matrices...\")\n",
        "K_train = quantum_kernel(X_train, X_train)\n",
        "K_test = quantum_kernel(X_test, X_train)"
      ],
      "metadata": {
        "id": "yw8vWcVmFo8C",
        "outputId": "1e088332-3dee-4106-918c-fab82703b701",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing quantum kernel matrices...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Train SVM with Precomputed Quantum Kernel\n",
        "print(\"Training Quantum Kernel SVM...\")\n",
        "svm = SVC(kernel='precomputed')\n",
        "svm.fit(K_train, y_train)"
      ],
      "metadata": {
        "id": "JrFEBK3LLqfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Evaluation\n",
        "y_pred = svm.predict(K_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "1CqS0CugLrnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Confusion Matrix Plot\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ef5_TOu1LsGY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
